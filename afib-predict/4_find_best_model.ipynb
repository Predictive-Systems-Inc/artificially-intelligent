{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try using linear regression to predict the label using the irregularity score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a support vector classifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results shape: (182, 15)\n",
      "X_train shape: (145, 14)\n",
      "X_test shape: (37, 14)\n",
      "y_train shape: (145,)\n",
      "y_test shape: (37,)\n"
     ]
    }
   ],
   "source": [
    "#load the results\n",
    "results = pd.read_csv('data/hrv_results.csv')\n",
    "results = results.dropna().drop('record_id', axis=1)\n",
    "print('results shape:', results.shape)\n",
    "\n",
    "X, y = results.drop('label', axis=1), results['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Score  Test Score   Runtime Top Predictor\n",
      "0  Logistic Regression     0.675862    0.567568  0.014606         pnn50\n",
      "           Model  Train Score  Test Score   Runtime Top Predictor\n",
      "0  Random Forest          1.0    0.675676  0.115502          nn50\n",
      "               Model  Train Score  Test Score   Runtime Top Predictor\n",
      "0  Gradient Boosting          1.0    0.756757  0.257548         pnn50\n",
      "                    Model  Train Score  Test Score    Runtime Top Predictor\n",
      "0  Support Vector Machine     0.731034    0.594595  21.463787   lf_hf_ratio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Top Predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>pnn50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>nn50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.257548</td>\n",
       "      <td>pnn50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>21.463787</td>\n",
       "      <td>lf_hf_ratio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Score  Test Score    Runtime Top Predictor\n",
       "0     Logistic Regression     0.675862    0.567568   0.014606         pnn50\n",
       "1           Random Forest     1.000000    0.675676   0.115502          nn50\n",
       "2       Gradient Boosting     1.000000    0.756757   0.257548         pnn50\n",
       "3  Support Vector Machine     0.731034    0.594595  21.463787   lf_hf_ratio"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00         0\n",
      "           N       0.86      0.79      0.83        24\n",
      "           O       0.75      0.75      0.75        12\n",
      "           ~       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.76        37\n",
      "   macro avg       0.40      0.39      0.39        37\n",
      "weighted avg       0.80      0.76      0.78        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mlmnl/Documents/GitHub/artificially-intelligent/.conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's use the following models to predict the label\n",
    "# 1. Linear Regression\n",
    "# 2. Random Forest\n",
    "# 3. Gradient Boosting\n",
    "# 4. Support Vector Machine\n",
    "\n",
    "result = pd.DataFrame(columns=['Model', 'Train Score', 'Test Score', 'Runtime', 'Top Predictor'])\n",
    "\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_score = accuracy_score(y_train, lr.predict(X_train))\n",
    "lr_test_score = accuracy_score(y_test, lr.predict(X_test))\n",
    "lr_runtime = time.time() - start_time\n",
    "top_predictor = X.columns[np.argmax(np.abs(lr.coef_[0]))]\n",
    "result = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression'],\n",
    "    'Train Score': [lr_train_score],\n",
    "    'Test Score': [lr_test_score],\n",
    "    'Runtime': [lr_runtime],\n",
    "    'Top Predictor': [top_predictor]\n",
    "})\n",
    "print(result)\n",
    "result = pd.concat([result], ignore_index=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_score = accuracy_score(y_train, rf.predict(X_train))\n",
    "rf_test_score = accuracy_score(y_test, rf.predict(X_test))\n",
    "rf_runtime = time.time() - start_time\n",
    "top_predictor = X.columns[np.argmax(rf.feature_importances_)]\n",
    "result_rf = pd.DataFrame({\n",
    "    'Model': ['Random Forest'],\n",
    "    'Train Score': [rf_train_score],\n",
    "    'Test Score': [rf_test_score],\n",
    "    'Runtime': [rf_runtime],\n",
    "    'Top Predictor': [top_predictor]\n",
    "})\n",
    "print(result_rf)\n",
    "result = pd.concat([result, result_rf], ignore_index=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_train_score = accuracy_score(y_train, gb.predict(X_train))\n",
    "gb_test_score = accuracy_score(y_test, gb.predict(X_test))\n",
    "gb_runtime = time.time() - start_time\n",
    "top_predictor = X.columns[np.argmax(gb.feature_importances_)]\n",
    "result_gb = pd.DataFrame({\n",
    "    'Model': ['Gradient Boosting'],\n",
    "    'Train Score': [gb_train_score],\n",
    "    'Test Score': [gb_test_score],\n",
    "    'Runtime': [gb_runtime],\n",
    "    'Top Predictor': [top_predictor]\n",
    "})\n",
    "print(result_gb)\n",
    "result = pd.concat([result, result_gb], ignore_index=True)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_train_score = accuracy_score(y_train, svm.predict(X_train))\n",
    "svm_test_score = accuracy_score(y_test, svm.predict(X_test))\n",
    "svm_runtime = time.time() - start_time\n",
    "top_predictor = X.columns[np.argmax(np.abs(svm.coef_[0]))]\n",
    "result_svm = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machine'],\n",
    "    'Train Score': [svm_train_score],\n",
    "    'Test Score': [svm_test_score],\n",
    "    'Runtime': [svm_runtime],\n",
    "    'Top Predictor': [top_predictor]\n",
    "})\n",
    "print(result_svm)\n",
    "result = pd.concat([result, result_svm], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "display(result)\n",
    "\n",
    "# Optional: Display detailed classification report for best model\n",
    "best_model_idx = result['Test Score'].idxmax()\n",
    "best_model_name = result.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    y_pred = lr.predict(X_test)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    y_pred = rf.predict(X_test)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    y_pred = gb.predict(X_test)\n",
    "else:\n",
    "    y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
